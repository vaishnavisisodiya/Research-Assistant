ğŸ§  Research Assistant
AI-Powered Research Paper Search & PDF Question Answering System
ğŸ“Œ Overview

Research Assistant is a full-stack AI application that helps users interact with academic research papers using Large Language Models (LLMs).
Instead of manually reading long research PDFs, users can upload documents, ask questions in natural language, and receive accurate, context-aware answers.

This project demonstrates a real-world implementation of LLMs, embeddings, vector databases, and Retrieval Augmented Generation (RAG).

ğŸ¯ Purpose of the Project

The traditional research workflow is slow and inefficient:

Reading long research papers takes a lot of time

Finding exact information inside PDFs is difficult

Comparing multiple papers manually is hard

ğŸ‘‰ This project was built to:

Simplify academic research using AI

Enable question-answering directly from research PDFs

Apply LLM concepts in a practical, real-world system

Learn and demonstrate end-to-end AI application development

âœ¨ Key Features
ğŸ” Research Paper Search

Search academic research papers using the arXiv API

Query papers by keyword or topic

Ask AI-based questions related to research papers

ğŸ“„ PDF Question Answering (RAG)

Upload research PDFs

Automatic text extraction

Chunking of large documents

Embedding generation for semantic understanding

Context-aware answers using vector similarity search

ğŸ’¬ Chat Interface

Real-time AI responses

Multiple chat sessions

Clean and interactive user interface

ğŸ” Authentication

User login and signup

Secure session handling

ğŸ—ï¸ System Architecture

Frontend (React + TypeScript)
â†“
Backend (FastAPI)
â†“
LLM (Language Model)
â†“
Vector Database (ChromaDB)

âš™ï¸ Tech Stack
Frontend

React

TypeScript

Tailwind CSS

Zustand (State Management)

Backend

Python

FastAPI

AI & Data

Large Language Models (LLMs)

Embeddings

ChromaDB (Vector Database)

Retrieval Augmented Generation (RAG)

ğŸ“ Project Structure

Research-Assistant/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ routers/
â”‚ â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ data/
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ hooks/
â”‚ â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md

â–¶ï¸ How to Run Locally
Backend

Go to backend directory

Install dependencies

Start FastAPI server

Commands:
cd backend
pip install -r requirements.txt
uvicorn main:app --reload

Frontend

Go to frontend directory

Install dependencies

Start development server

Commands:
cd frontend
npm install
npm run dev

ğŸ§ª Example Use Cases

Ask questions from uploaded research PDFs

Summarize long research papers

Understand complex research topics in simple language

Speed up academic research work

ğŸ“š What I Learned

End-to-end LLM-based application development

Working with embeddings and vector databases

Implementing Retrieval Augmented Generation (RAG)

Full-stack AI system design

Solving real-world problems using AI
